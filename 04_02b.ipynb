{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4762486a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h1>Deep Learning with Python using Keras</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11963cc7",
   "metadata": {},
   "source": [
    "Deep learning has revolutionized the field of machine learning, enabling significant advancements in areas such as computer vision, natural language processing, and speech recognition. In this tutorial, we'll embark on our deep learning journey by learning how to design and build a deep learning model using Keras, a user-friendly and high-level neural networks API, written in Python and capable of running on top of TensorFlow. Keras allows for easy and fast prototyping of deep learning models.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will:\n",
    "+ Understand the basics of Keras.\n",
    "+ Know how to load and preprocess data.\n",
    "+ Know how to define a deep learning model in Keras.\n",
    "+ Understand how to compile a Keras model.\n",
    "+ Know how to train and save a model.\n",
    "\n",
    "## Prerequisites\n",
    "Before we begin, ensure you have:\n",
    "\n",
    "+ Basic knowledge of Python programming (variables, functions, classes).\n",
    "+ Familiarity with fundamental machine learning concepts (datasets, training/testing, overfitting).\n",
    "+ A Python (version 3.x) environment with the `tensorflow`, `keras`, `numpy`, and `matplotlib` packages installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887bb87",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>1. Import the Libraries</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96c17b",
   "metadata": {},
   "source": [
    "To start, we'll import the necessary libraries that we'll use throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c664ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff3ec92",
   "metadata": {},
   "source": [
    "The libraries we imported are:\n",
    "+ **numpy:** A fundamental package for scientific computing in Python, used for handling arrays and mathematical functions.\n",
    "+ **tensorflow:** An open-source platform for machine learning developed by Google.\n",
    "+ **keras:** A high-level API for building and training deep learning models, integrated within TensorFlow.\n",
    "+ **layers:** A module in Keras containing various types of neural network layers.\n",
    "\n",
    "To ensure reproducibility of my code, so you obtain the same results as my example, I will set a random initialization seed using the `keras.utils.set_random_seed()` function. This will make the weights and biases initialized during the training process deterministic, ensuring consistent results across different runs. However, in practice, setting a seed is not typically necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c6b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685885f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>2. Load the Data</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea22993f",
   "metadata": {},
   "source": [
    "For this tutorial, we'll use the **MNIST dataset**, a classic dataset in the machine learning community. It consists of 70,000 grayscale images of handwritten digits ranging from 0 to 9. Each image is 28x28 pixels, and the dataset is divided into 60,000 training images and 10,000 testing images. Our goal will be to develop a model that learns to correctly identify a handritten digit given the image.\n",
    "\n",
    "Keras provides easy access to the MNIST dataset via its datasets module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53e3b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e348b40",
   "metadata": {},
   "source": [
    "The `keras.datasets.minist.load_data()` function returns four datasets:\n",
    "+ **train_images:** A numpy array of training images.\n",
    "+ **train_labels:** A numpy array of training labels.\n",
    "+ **test_images:** A numpy array of testing images.\n",
    "+ **test_labels:** A numpy array of testing labels.\n",
    "\n",
    "Let's take a moment to understand the data we're working with. We start by getting the shape of the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data shape:', train_images.shape)\n",
    "print('Testing data shape:', test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd4a81",
   "metadata": {},
   "source": [
    "The output tells us that:\n",
    "+ The training data consists of 60,000 images, each of size 28x28 pixels.\n",
    "+ The test data consists of 10,000 images, each of size 28x28 pixels.\n",
    "\n",
    "Visualizing some samples can provide further intuition about the dataset. Let's display the first 5 images in the training set along with their associated labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac953fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(5):\n",
    "    plt.imshow(train_images[i], cmap = 'gray')\n",
    "    plt.title(f'Label: {train_labels[i]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa17d3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>3. Preprocess the Data</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceed43f",
   "metadata": {},
   "source": [
    "Before feeding the data into our deep learning model, we need to preprocess it to ensure optimal performance. Neural networks in Keras expect the input data to be in a specific shape. We're going to build a simple feedforward neural network (also known as a multilayer perceptron). This type of network expects the incoming data as a vector.\n",
    "\n",
    "This means we need to flatten the 28x28 images into vectors of size 784 (i.e. 28 $\\times$ 28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414cf0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(60000, 28 * 28)\n",
    "test_images = test_images.reshape(10000, 28 * 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c1ba2-1ff3-44df-bc01-33a3836349fc",
   "metadata": {},
   "source": [
    "Let's get the shape of the training and test sets again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c659f-51a8-4e37-addd-9e2ab3e2e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data shape:', train_images.shape)\n",
    "print('Testing data shape:', test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19040ba6",
   "metadata": {},
   "source": [
    "Now, `train_images` and `test_images` have shapes (60000, 784) and (10000, 784), respectively.\n",
    "\n",
    "Pixel values in images range from 0 to 255. Neural networks perform better when input values are scaled to a smaller range, typically between 0 and 1. To accommodate this, we convert the data type of the image pixels to float32 and normalize the values to fall within 0 and 1 by dividing them by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68797c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7335fcb",
   "metadata": {},
   "source": [
    "The label values associated with each image are integers from 0 to 9. For multi-class classification, it's standard to convert these labels into one-hot encoded vectors. One-hot encoding involves representing categorical variables as binary vectors. For instance, label '0' becomes [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] and label '9' becomes [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ab788",
   "metadata": {},
   "source": [
    "Now, `train_labels` and `test_labels` are matrices of shape (60000, 10) and (10000, 10), respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c95c2e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>4. Define the Model Architecture</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f001a",
   "metadata": {},
   "source": [
    "A neural network's architecture defines how the data flows through the model, how layers are connected, and what operations are performed. To define the architecture of our model, we'll use the **Sequential API** in Keras, which allows us to build models layer by layer.\n",
    "\n",
    "We start by initializing the Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa0d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f3d333a",
   "metadata": {},
   "source": [
    "Then we specify the shape of the input data. This represents the input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1a124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72154c2c",
   "metadata": {},
   "source": [
    "Next, we add two fully connected (or dense) layers - one with 512 neurons, and the other with 128 neurons. We use the Rectified Linear Unit (ReLU) activation function for both. Recall that the ReLU activation function introduces non-linearity into a model and helps with the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd1cc29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e47e4eb",
   "metadata": {},
   "source": [
    "For this simple model, we'll limit the architecture to a two hidden layers and proceed directly to the output layer. In more complex models, we can add multiple hidden layers to capture intricate patterns in the data.\n",
    "\n",
    "The ouput layer contains 10 neurons corresponding to the 10 classes (digits 0-9) and uses the softmax activation function to convert the raw score output of the model to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02197ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f50d219",
   "metadata": {},
   "source": [
    "Rather than adding each layer of the model one by one, we can also define the entire model at once as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9492c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae748b5a",
   "metadata": {},
   "source": [
    "We can view a summary of the model architecture by calling the `summary()` method of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb6a2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaa3f850",
   "metadata": {},
   "source": [
    "The output shows the total number of parameters (weights and biases in each layer) that will be trained for the model.\n",
    "\n",
    "+ First Hidden Layer: 784 inputs $\\times$ 512 neurons + 512 biases = 401,920 parameters.\n",
    "+ Second Hidden Layer: 512 inputs $\\times$ 128 neurons + 128 biases = 65,664 parameters.\n",
    "+ Output Layer: 128 inputs $\\times$ 10 neurons + 10 biases = 1,290 parameters.\n",
    "\n",
    "A total of **468,874** weights and biases will be trained for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bade21",
   "metadata": {},
   "source": [
    "Visually, the neural network we just defined can be represented in the following way:\n",
    "\n",
    "<img src=\"nnet.jpg\" width=\"50%\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
